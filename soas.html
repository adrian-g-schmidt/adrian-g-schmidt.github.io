---
permalink: /portfolio/system-of-a-sound
---


<!DOCTYPE html>
<html>

<head>
    <title>Adrian Schmidt</title>
    <link rel="icon" type="image/svg+xml" href="/images/icon.svg">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="/assets/css/big-portfolio.css">
</head>

<body>

    <div id="navbar" class="smaller-text">
        <a href="/">
            <h2>
                <span class="l1">A</span><span class="w1">DRIAN</span>
                <br>
                <span class="l2">S</span><span class="w2">CHMIDT</span>
            </h2>
        </a>
        
        <div>
            <div class="icon-parent">
                <a href="javascript:void(0);" class="icon" onclick="hamburger()">
                    <div class="ham"></div>
                    <div class="ham"></div>
                    <div class="ham"></div>
                </a>
            </div>
            <div id="links">
                <a href="/assets/adrian-schmidt-resume.pdf" style="font-weight:bold; padding: 0px 20px;">
                    Resume
                </a>
                <a href="/#portfolio" style="font-weight:bold; padding: 0px 20px;">
                        Portfolio
                </a>
                <a href="/#contact" style="font-weight:bold; padding: 0px 20px;">
                    Contact
                </a>
            </div>
         </div>


    </div>

    <div id="content">
        <div id="cover" style="background-image: url('/assets/images/soas/soas-banner.jpg'); ">
            <img id="title-small" src="/assets/images/soas/soas-text.svg">

            <figure>
                <video width="100%" controls>
                    <source src="/assets/images/soas/soas-video.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>           
                <figcaption>Clips of interacting with System of a Sound.
                </figcaption>
            </figure>

            <p>
            <img id="title-big" src="/assets/images/soas/soas-text.svg">
            <strong>Role:</strong> Visual Design and Programming.
            <br><br>
            <strong>Tools:</strong> Illustrator, p5.js, HTML, JavaScript, and Python.
            <br><br>
            <strong>Description:</strong> System of a Sound is an immersive audio installation, taking live data elements from the internet to piece together a generated sound-scape of music. Viewers interact with the artwork by moving their arms to strum accompaniments to the generated music. The overall piece takes data from around the Birch building and transforms it into music so the viewer can understand and relate to the meaning of the data. 
            </p>
        </div>

        <div id="study">

        <h2>
            <span class="l1">P</span><span class="w1">ACE <i>&</i></span>
            <br>
            <span class="l2">M</span><span class="w2">USIC</span>
        </h2>
        <p>
            System of a Sound is an experience created as part of the Birch Research Project at the ANU School of Cybernetics. The research project investigates peoples connection to place, and System of a Sound explores linking data to emotion to music. 
            <br><br>
            The intellectual core of the experiences is Stewart Brand and Brian Eno’s “Pace Layers”. The Pace Layers describe the world in layers of stability, with the more stable layers supporting the more fluid ones. The upper layers can change more rapidly due to the support of the layers they are built upon. 
            <figure>
            <img src="/assets/images/soas/pace-diagram.jpg" 
                alt="A diagram showing layers of a global system ordered from less stable to more stable">
                <figcaption>Pace Layering - diagram by Stewart Brand, from The Clock of the Long Now, 1999.
                </figcaption>
            </figure>
            System of a Sound uses the Pace Layers to investigate our building through different data types, giving the viewer an understanding of the buildings and their context through the medium of sound.
            <figure>
                <img src="/assets/images/soas/proposal.png" 
                alt="A diagram of concentric circle with data labels" class="tall">
                <figcaption>The original diagram for the visuals of System of a Sound - diagram by Josh Andres, School of Cybernetics.
                </figcaption>
            </figure>
            System of a Sound was commissioned in collaboration with the music production group Uncanny Valley, which uses emerging technologies to generate dynamic and modern sound-scapes and songs. 
            <br><br>
            I joined the project to help design and implement the visual components of the work. Working with the researchers and artists, I prototyped, iterated, and built the display interface for users to interact with, understand the data, and contribute to the music. 
        </p>

        <h2>
            <span class="l1">D</span><span class="w1">ATA</span>
            <br>
            <span class="l2">D</span><span class="w2">ISPLAY</span>
        </h2>       
        <p>
            Experimenting with ways data could be displayed over a circle on a vertical screen, I created the following designs. Each layer is placed within another and can be highlighted to show more information. They can be rotated using gestures to view the data over time. A viewer interacting with each layer affects the music, with each layer acting like a fluid. The layers would have a viscosity that varied depending on the “pace” of that layer.
            <figure>
                <div class="img-grid">
                <img src="/assets/images/soas/circle-draft.jpg" 
                alt="The un-highlighted state">
                <img src="/assets/images/soas/circle-draft-highlight.jpg" 
                alt="The highlighted state">
                </div>
                <figcaption>A mock-up of the un-highlighted state, where a viewer would create music, and the highlighted state, where the viewer can read the underlying data.
                </figcaption>
            </figure>
            The project lead desired a more direct representation of time in the design, and suggested using a spiral to display the information. I tested this idea using Python to take information and project it onto a spiral, making the following two plots. The three data feeds displayed are Canberra CO<sub>2</sub> measurements, electricity usage of the Birch Building, and temperature data of Canberra. As most of our intended data types increase/decrease in a near linear fashion we found these visualisations obscured the trends.
            <figure>
                <div class="img-grid">
                <img src="/assets/images/soas/python-lines.png" 
                alt="Data projected over a spiral with a running line">
                <img src="/assets/images/soas/python-dots.png" 
                alt="Data represented over a spiral by circle sizes">
                </div>
                <figcaption>Plotting data over a spiral, with information displayed by varying the line height, and by the size of each circle.
                </figcaption>
            </figure>
            A programmer with Uncanny Valley had been experimenting with the large language model GPT-3 and found that it could make insightful and descriptive data representations. GPT-3 is trained off 45TB of text data to predict the most likely next word in a sentence, and by giving it the data, we could get text descriptions of the data. He suggested going back to the original Pace layers and using a horizontal screen instead of a vertical one. Based on his suggestions, I created the following design, where each line of text moves with a speed corresponding to that layer. We all agreed this was the right approach for the project. 
            <figure>
                <img src="/assets/images/soas/pace-draft.jpg" 
                alt="A mock-up of the display, using the AI Generated text descriptions of each layers data.">
                <figcaption>A mock-up of the display, using the AI Generated text descriptions of each layers data.
                </figcaption>
            </figure>
        
        </p>

        <h2>
            <span class="l1">P</span><span class="w1">OSING <i>for</i></span>
            <br>
            <span class="l2">S</span><span class="w2">OUND</span>
        </h2>        <p>
            We explored different way the viewer could interact to create music using gesture tracking. Building on our collaborators ideas of using a grid of notes, I looked for ways to incorporate the interaction into the pace layer design. The final design was inspired by the strings on a guitar. The lower lines are thicker, playing lower notes and vibrating for longer. The thinner strings play higher notes and quickly stop vibrating, matching that layer’s faster ’pace’.
            <br><br>
            I created the interaction and animation for the strings in p5.js. I designed the string as a combination of Gaussian distributions and Sin waves. Once I had a functional model, I refined the string dynamics so the line would feel like you were physically plucking it. The equation of the string dynamics is:
            <br><br>
            <img src="/assets/images/soas/equation.svg" style="width: 100%;">
            <br><br>
            Where <img src="/assets/images/soas/x.svg"> is position along the string, <img src="/assets/images/soas/hx.svg"  style="transform: translate(0px,2px)"> and <img src="/assets/images/soas/hy.svg" style="transform: translate(0px,5px)"> are the hand's x and y positions respectively, <img src="/assets/images/soas/omega.svg"> is the wavelength, <img src="/assets/images/soas/gauss.svg" style="transform: translate(0px,5px)"> is a normalised Gaussian probability distribution function at position <img src="/assets/images/soas/x.svg">, <img src="/assets/images/soas/tmax.svg" style="transform: translate(0px,2px)"> is the time for the string to stop vibrating, <img src="/assets/images/soas/t.svg"> is the current time, <img src="/assets/images/soas/s.svg"> is the spread speed, <img src="/assets/images/soas/d.svg"> is the direction, and <img src="/assets/images/soas/o.svg"> is the y offset. Additional functions calculate whether a string is being interacted with, and from which direction. 
            <br><br>
            The viewer’s hand position is represented by a circle. A recording of the string is shown below. 
            <figure>
                <video width="100%" controls>
                    <source src="/assets/images/soas/animation.webm" type="video/webm">
                Your browser does not support the video tag.
                </video>    
                <figcaption>The string plucking animation</figcaption>
            </figure>
        </p>

        <h2>
            <span class="l1">S</span><span class="w1">TYLE</span>
            <br>
            <span class="l2">S</span><span class="w2">ELECTION</span>
        </h2>        <p>
            After designing the string dynamics, I created a series of skins for the design, primarily to demonstrate to my colleagues that we could experiment with alternative colour schemes, fonts, and layouts. 
            <figure>
                <img src="/assets/images/soas/skins.png" 
                alt="Four skins of the running interface, created to demonstrate ease of adjusting the design">
                <figcaption>Four skins of the running interface, created to demonstrate ease of adjusting the design
                </figcaption>
            </figure>
            From these designs, we decided to bring in more elements from the original Pace Layers diagram. These included the curve, upper and lower lines, category descriptions, original font, and an inverted colour scheme. 
            <figure>
                <img src="/assets/images/soas/pace-version.jpg" 
                alt="The interface with more direct references and features of the Pace layers diagram.">
                <figcaption>The interface with more direct references and features of the Pace layers diagram.
                </figcaption>
            </figure>
            Unfortunately, the combination of curved words and hand tracking was computationally expensive, running at a lower frame rate. I tested several straight-line designs with viewers who had varying knowledge of the Pace layers to find which would best evoke the curve. Bending the line pattern on the top and bottom made these layers feel part of a whole while keeping the centre lines straight. The final interface design can be seen below.
            <figure>
                <img src="/assets/images/soas/final.jpg" 
                alt="The final interface design.">
                <figcaption>The final interface design.
                </figcaption>
            </figure>
        </p>
        <h2>
            <span class="l1">F</span><span class="w1">INALISING <i>&</i></span>
            <br>
            <span class="l2">F</span><span class="w2">UTURE</span>
        </h2>        
        <p>
            To finalise the design of the interface, we wanted colours to appear when you interact with the artwork – bringing further dynamism to the systems that form the Birch building. These elements needed to be dynamic but not distract from the primary content. I achieved this by adding coloured circles that expand out when you play notes. They appear, grow, and fade out, accompanying each new note the viewer plays.
            <figure>
                <img src="/assets/images/soas/colours.jpg" 
                alt="A close up of the coloured circles expanding as a viewer would play new notes.">
                <figcaption>A close up of the coloured circles expanding as the viewer plays new notes.
                </figcaption>
            </figure>
            As plans grew to share System of a Sound with the press, we needed to improve the starting experience. The software runs entirely in the web browser, needing a button to start the music due to web browsers not allowing music to play automatically. We also needed to cover loading, as the hand-tracking software can take between 1 and 20 seconds to load, depending on Australian internet speeds. The School is also very cognisant of privacy and wanted to display a privacy statement about the camera tracking data. 
            <br><br>
            I added a splash screen to cover these issues, with a loading display, artwork description, privacy statement, and a continue button that activates the music. Camera tracking requires decent computing power, and the quality depends on the environment and lighting around the viewer. To provide a more robust interface I developed a mouse only interaction mode. This mode gives an alternative method of interaction for those with inappropriate web cam set-ups, privacy concerns, less powerful computers, or accessibility needs.
            <br><br>
            There are plans for System of a Sound to tour other buildings, with different data inputs and modes of interaction depending on the building. We will also begin observing how interacting with the exhibit changes people’s perceptions of the built environment and surrounding world.
            <figure>
                <img src="/assets/images/soas/splash.jpg" 
                alt="The splash screen after loading.">
                <figcaption>The splash screen after loading.
                </figcaption>
            </figure>
        </p>
        <h2>
            <span class="l1">R</span><span class="w1">ESULTS <i>&</i></span>
            <br>
            <span class="l2">R</span><span class="w2">EFLECTIONS</span>
        </h2>        
        <p>
            The final piece was placed within a fabric dome for the School of Cybernetics Launch Exhibition ‘Australian Cybernetic: a Point Through Time’. It has been wonderful seeing people enter, play, and listen with the piece, interacting with the sound-scape generated from data sources all around them. 
            <br><br>
            I learned a lot over the course of this project, including translating between different artistic visions. This was my first experience making an interactive interface. Learning p5.js to translate mock-ups from Illustrator to the web has been a great pathway into using more complex JavaScript libraries. 
            <figure>
                <img src="/assets/images/soas/poster.jpg" 
                alt="Poster showing how different data sources are combined to create the soundscape.">
                <figcaption>Poster for the artwork designed by Ken Wheeler
                </figcaption>
            </figure>
            You can try System of a Sound for yourself <a href="http://systemofasound.herokuapp.com">here</a>, and read Gizmodo's article about it <a href="https://www.gizmodo.com.au/2022/11/anu-ai-music-experience/">here</a>.
            <br><br>
            <strong>Project team:</strong> Josh Andres, Oliver Bown, Charlton Hill, Rodolfo Ocampo, Caroline Pegram, Adrian Schmidt, Justin Shave, Brendan Wright.
            <br>
            <br>
        </p>

        <div style="text-align: center; padding-bottom: 50px; font-size: 20px;">
        <a class ='noselect' href="/#portfolio">
            Return to Portfolio
        </a>
        </div>


        </div>
    </div>
    
</body>


<script src="/assets/js/words-anim.js"></script>


</html>